{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5aad2334-562a-49da-ac8b-cb8d3399fc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d04f928-d3ce-47a2-83e5-2f8ab7c5cbca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbbe4c81500145a190bf454a96a37757",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\hp\\.cache\\huggingface\\hub\\models--distilbert--distilbert-base-uncased-finetuned-sst-2-english. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hp\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33267df5f6ae4b16a5a6204815556ecf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7414be06d57e4cc1b68e36e80d62668c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31d070fb0ed040a999b7b1565855013c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision 4c53496 (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c16eeaa0ca744f6e9ef4d5a1f875489f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/998 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\hp\\.cache\\huggingface\\hub\\models--dbmdz--bert-large-cased-finetuned-conll03-english. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66199169287e4f208b136e6d914e4c55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.33G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------- #\n",
    "#                             NLP                                     #\n",
    "# ------------------------------------------------------------------- #\n",
    "\n",
    "classifier = pipeline(\"text-classification\")\n",
    "token_classifier = pipeline(\"token-classification\")\n",
    "question_answer = pipeline(\"question-answering\")\n",
    "text_generation = pipeline(\"text-generation\")\n",
    "summarizer = pipeline(\"summarization\")\n",
    "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-fr\")\n",
    "text2text_generator = pipeline(\"text2text-generator\")\n",
    "fill_mask = pipeline(\"fill-mask\")\n",
    "feature_extractor = pipeline(\"feature-extraction\")\n",
    "sentence_similarity = pipeline(\"sentence-similarity\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fa8b8e-0a3f-4032-8502-e663c25eacb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------- #\n",
    "#                         Computer Vision                             #\n",
    "# ------------------------------------------------------------------- #\n",
    "\n",
    "image_classifier = pipeline(\"image-classification\")\n",
    "object_detection = pipeline(\"object-detection\")\n",
    "image_segmenter = pipeline(\"image-segmentation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1540d0bf-7385-4131-b6cf-f76d9ad95c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------- #\n",
    "#                         Speech Processing                           #\n",
    "# ------------------------------------------------------------------- #\n",
    "\n",
    "speech_recognizer = pipeline(\"automatic-speech-recognition\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be714b01-e559-4fcf-8eee-994fb1c25863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------- #\n",
    "#                            Multimodels                              #\n",
    "# ------------------------------------------------------------------- #\n",
    "\n",
    "image_captioner = pipeline(\"image-to-text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bcdebe-1cb3-4e1d-8b36-e3281b62a743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------- #\n",
    "#                             Other TASKS                             #\n",
    "# ------------------------------------------------------------------- #\n",
    "\n",
    "table_qa = pipeline(\"table-question-answering\")\n",
    "doc_qa = pipeline(\"document-question-answering\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d85818-78a2-4883-8e39-bd50ed8826e1",
   "metadata": {},
   "source": [
    "## NLP Tasks ??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a773d83-efb4-4d34-935f-a260509e7dc8",
   "metadata": {},
   "source": [
    "#### Sentiment Analysis ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e75947b4-1bc2-4205-b92a-db59a1bb3b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'NEGATIVE', 'score': 0.9997795224189758}]\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "result = classifier(\"I was so not happy with the last Mission Impossible Movie\")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6e3aafe-2080-4229-ac0e-5ab38fb840c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9992005228996277}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline(task=\"sentiment-analysis\")(\"I was confused with the Barbie Movie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4cdd2965-35d2-4759-a11a-88234588c0ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.983845591545105}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline(task=\"sentiment-analysis\")(\"Everyday lots of LLMs papers are published about LLMs Evaluation.\\\n",
    "                                     Lots of them Looks very Promising.\\\n",
    "                                     I am not sure if we can actually evaluate LLMs.\\\n",
    "                                     There is still lots to do.\\\n",
    "                                     Don't you think??\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76710ea8-2432-4ee1-bfd7-2128ec128687",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline(task=\"sentiment-analysis\", model=\"facebook/bart-large-mnli\")\\\n",
    "                                   (\"Everyday lots of LLMs papers are published about LLMs Evaluation.\\\n",
    "                                     Lots of them Looks very Promising.\\\n",
    "                                     I am not sure if we can actually evaluate LLMs.\\\n",
    "                                     There is still lots to do.\\\n",
    "                                     Don't you think??\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54613410-c62a-44d6-8f75-16362c7461da",
   "metadata": {},
   "source": [
    "#### Batch Sentiment Analysis ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0294b000-c5d0-4394-8a49-a6f8a276c8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9987209439277649},\n",
       " {'label': 'NEGATIVE', 'score': 0.9995476603507996},\n",
       " {'label': 'NEGATIVE', 'score': 0.9983083009719849},\n",
       " {'label': 'NEGATIVE', 'score': 0.9881011247634888}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(task=\"sentiment-analysis\")\n",
    "\n",
    "task_list = [\"I really Like AutoEncoder, best models for Anomaly Detection\",\\\n",
    "             \"I am not sure if we can actually evaluate LLMs.\",\\\n",
    "             \"PassiveAgressive is the name of a Linear Regression Model that so many people do not know.\",\\\n",
    "             \"I hate long meeting.\"]\n",
    "\n",
    "classifier(task_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a2fa7db-b0ea-4acf-b1bb-6e5010c82ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ce91e71723e40a791b3de74a40bf009",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.92k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\hp\\.cache\\huggingface\\hub\\models--SamLowe--roberta-base-go_emotions. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "553d59fc12be4ff9b29e264557edcd8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13506a8f53674b5990e70296bfe6428b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/380 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bb8d462f429429aadb17e48afd261dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3f676b47b17495aae95a85ccbbce624",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a54dc395043f470281f48b14844440e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92b380d6b2344a299bef3b21866eb5a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/280 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'admiration', 'score': 0.7196842432022095},\n",
       " {'label': 'confusion', 'score': 0.9048526883125305},\n",
       " {'label': 'neutral', 'score': 0.7837756872177124},\n",
       " {'label': 'anger', 'score': 0.7925533056259155}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(task=\"sentiment-analysis\", model=\"SamLowe/roberta-base-go_emotions\")\n",
    "\n",
    "task_list = [\"I really Like AutoEncoder, best models for Anomaly Detection\",\\\n",
    "             \"I am not sure if we can actually evaluate LLMs.\",\\\n",
    "             \"PassiveAgressive is the name of a Linear Regression Model that so many people do not know.\",\\\n",
    "             \"I hate long meeting.\"]\n",
    "\n",
    "classifier(task_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab55ce3-03b9-4095-a7a6-62f2772970e3",
   "metadata": {},
   "source": [
    "#### Text Generation ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "44051bf8-8a23-43ae-a00a-bcc15f316c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to openai-community/gpt2 and revision 607a30d (https://huggingface.co/openai-community/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf294eb506b348ecb96b6732b15e55de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\hp\\.cache\\huggingface\\hub\\models--openai-community--gpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98cdb1eca92d4e9e9fb6b51ba2e88360",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9ec091f82fd4f40bf9b1b25ca2ee107",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a42b78c2e443486da45e4daca7994bc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28d1fc30304e4d3ea882df8da5aa475f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46463cb28f5e4b3f82c63e33303ac2d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "756431c22b054e85a2b46a0fd10c2704",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated_Text:\n",
      " Today is a rainy day in Landon. I'm going to have to go to bed early, and I'm going to have to make sure I'm awake for the night.\"\n",
      "\n",
      "\"It's a nice day, it's a nice day for us,\" says Simeon. \"It's a nice day for us.\"\n",
      "\n",
      "\"Just go out there and pick up your backpack,\" says Simeon. \"I'll go somewhere and pick it up, and I'll go to bed. I'm going to go out there and pick up my backpack, and I'm going to go to bed.\"\n",
      "\n",
      "Simeon does not know how long it will take him to get home from work and back, but he does want to pick up some of his belongings. He has three kids, and he's always been prepared to go back to work.\n",
      "\n",
      "\"I'm going to be back and I'm going to be ready to go home,\" says Simeon. \"I'm just going to go out there and pick up my backpack and I'm going to go to bed. I'm going to go out there and pick up my backpack, and I'm going to go to bed.\"\n",
      "\n",
      "Simeon says he wants to spend the night at a friend's house and get\n"
     ]
    }
   ],
   "source": [
    "text_generator = pipeline(task=\"text-generation\")\n",
    "\n",
    "generated_text = text_generator(\"Today is a rainy day in Landon\", truncation=True, num_return_sequences=2)\n",
    "\n",
    "print(\"Generated_Text:\\n\", generated_text[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bdbc50b2-bbc2-4703-b28a-2b83c930b2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 564e9b5 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffef9b464e764202bbd2754aa7994c30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/473 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\hp\\.cache\\huggingface\\hub\\models--distilbert--distilbert-base-cased-distilled-squad. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc1b3c13e2a646e08eb6e7a351554dee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/261M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af2078171c8941b3a2b14b84fc45c3a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b67efe66720644d1b26d9e44ca8d1921",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a2209265ed2472ea34c5830f78564b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.46452516317367554,\n",
       " 'start': 29,\n",
       " 'end': 49,\n",
       " 'answer': 'Developing AI Models'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_model = pipeline(\"question-answering\")\n",
    "\n",
    "question = \"What is my job?\"\n",
    "context = \"My name is Mohamed, and I am Developing AI Models With Python.\"\n",
    "\n",
    "qa_model(question=question, context=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c85a01-89b0-4437-b425-1917059054e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
